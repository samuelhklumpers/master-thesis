\documentclass[10pt]{article}

\usepackage[style=alphabetic]{biblatex}
\addbibresource{refs.bib}

\usepackage{comment}

\setlength{\marginparwidth}{2cm} % remove when done

\usepackage{todonotes}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}

%\hypersetup{
%    colorlinks=true,
%    linkcolor=cyan
%    }

\usepackage{catchfilebetweentags}
\usepackage{quiver} 
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{longtable}
\usepackage{amsthm}
\usepackage{amsmath}


\theoremstyle{plain}% default
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem*{cor}{Corollary}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{example}{Example}[section]

\renewcommand{\partautorefname}{Part}%
\renewcommand{\sectionautorefname}{Section}%
\renewcommand{\subsectionautorefname}{Subsection}%

\providecommand{\theoremautorefname}{Theorem}%
\providecommand{\lemmaautorefname}{Lemma}%
\providecommand{\propautorefname}{Proposition}%
\providecommand{\conjectureautorefname}{Conjecture}%
\providecommand{\corautorefname}{Corollary}%

\providecommand{\defnautorefname}{Definition}%
\providecommand{\remarkautorefname}{Remark}%
\providecommand{\exampleautorefname}{Example}%
\providecommand{\claimautorefname}{Claim}%


\usepackage[links]{agda}
%\AtBeginEnvironment{code}{\fontsize{8}{10}}
\AgdaNoSpaceAroundCode{}

% from: https://agda.readthedocs.io/en/v2.6.3/_downloads/59877ce886494c991a213f09e29b712c/article-luaxelatex-different-fonts.lagda.tex
\usepackage{fontspec}

\usepackage{luaotfload}

\directlua{luaotfload.add_fallback
  ("myfallback",
    { "JuliaMono:style=Regular;"
    , "NotoSansMono:style=Regular;"
    , "NotoSansMath:style=Regular;"
    , "Segoe UI Emoji:mode=harf;"
    }
  )}
\defaultfontfeatures{RawFeature={fallback=myfallback}}

\setmainfont{Latin Modern Roman}

\newfontfamily{\AgdaSerifFont}{JuliaMono Regular}[Scale=0.8]
\newfontfamily{\AgdaSansSerifFont}{JuliaMono Regular}[Scale=0.8]
\newfontfamily{\AgdaTypewriterFont}{JuliaMono Regular}[Scale=0.8]
\setmonofont{JuliaMono Regular}[Scale=0.8]
\renewcommand{\AgdaFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaKeywordFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaStringFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaCommentFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaBoundFontStyle}[1]{\textit{\AgdaSerifFont{}#1}}

\definecolor{git-green}{HTML}{13A10E}
\definecolor{git-orange}{HTML}{C69026}

\newcommand{\added}[1]{\textcolor{git-green}{+#1}}
\newcommand{\changed}[1]{\textcolor{git-orange}{$\bullet$#1}}
\newcommand{\towrite}[1]{\todo[color=cyan]{#1}}
\newcommand{\toremove}[1]{\textcolor{red}{This is going to be (re)moved: ``#1''}}


% macros
\newcommand{\investigate}[1]{\par\vspace{1\baselineskip}\textcolor{gray}{#1}\vspace{1\baselineskip}\par}

% symbols
\newcommand{\bN}{\AgdaDatatype{ℕ}}
\newcommand{\bL}{\AgdaDatatype{Leibniz}}


\title{Ornaments and Proof Transport applied to Numerical Representations}
\author{Samuel Klumpers\\6057314}


\begin{document}
\maketitle

%\begin{abstract}
%This thesis explains the concepts of the structure identity principle, numerical representations, and ornaments, and aims to combine these to simplify the presentation and verification of finger trees, demonstrating the generalizability and improved compactness and security of the resulting code. Consequently, we also investigate to which extent ornaments, and other generic programs relying on axiom K, remain applicable in the cubical setting required for the structure identity principle.
%\end{abstract}

\tableofcontents

\listoftodos

\section{Introduction}\label{sec:intro}
\input{Introduction}

\subsection{The Problem}
The main question of this project is: \textit{can we describe finger trees \cite{fingertrees} in the frameworks of numerical representations and ornamentation \cite{progorn}, simplifying the verification of their properties as flexible two-sided arrays?}\todo{Revisit this when further} This question generates a number of interesting subproblems, such as that the number system corresponding to finger trees has many representations for the same number, which we expect to describe using quotients \cite{cuagda} and reason about using representation independence \cite{iri}. %If this is accomplished or deemed infeasible at an early stage, we can generalize the results we have to other related problems; for example, we may view the problem of generating arbitrary values for testing as an instance of an enumeration problem.


\subsection{Contributions}
In this paper, we:\todo{Revisit this when further}
\begin{itemize}
    \item[x] Adapt ornaments to nested types.
    \item[x] Allow ornaments to refer to sub-ornaments.
    \item[x] Define a small universe of typical number systems.
    \item[x] Give a generic derivation of numerical representations as ornaments from these number systems.
%    \item Instantiate a Structure Identity Principle for these representations.
\end{itemize}
We follow this up by enumerating these, and more structures. We:
\begin{itemize}
    \item[x] Define hierarchies to enumerate terms by levels.
    \item[x] Track the cardinalities of each level.
    \item Include parametrized datatypes into this setup.
    \item Modify this to include nested types.
    \item[?] Adapt this approach to index-first datatypes.
    \item Iterate the accessible indices per level.
\end{itemize}
Along the way, we also:
\begin{itemize}
    \item[x] Characterize identities of W-types.
    \item[x] Express heterogeneous variants of datastructures as ornaments.
\end{itemize}


\part*{Background}\label{part:background}
\addcontentsline{toc}{part}{\nameref{part:background}}
\input{Background}


\part{Descriptions and ornaments}
\input{Ornaments}


\part{Numerical representations}
%\section{Types from Specifications: Ornamentation and Calculation}\label{sec:numrep}
\input{TypeGeneration}


\part{Enumeration}
\input{Enumeration}


%\part{Temporary}

\part{Related work}\label{part:related}
\section{Descriptions and ornaments}
We compare our implementation to a selection of previous work, considering the following features


\begin{tabular}{c | c c c c c}
             & Haskell        & \cite{initenough} & \cite{levitation} & \cite{algorn} & \cite{progorn} \\
    \hline                                                                                             
    Fixpoint & yes*           & yes               & no                & yes?          & yes            \\
    Index    & —              & —                 & first**           & equality      & first          \\
    Poly     & yes            & 1                 & external          & external      & external       \\
    Levels   & —              & —                 & no                & no            & no             \\
    Sums     & list           & —                 & large             & large         & large          \\
    IndArg   & any            & any               & $\dots \to X\ i$  & $X\ i$        & $X\ i$         \\
    Compose  & yes            & yes               & no                & no            & no             \\
    Extension& —              & —                 & no                & —             & —              \\
    Ignore   & —              & —                 & —                 & —             & —              \\
    Set      & —              & —                 & —                 & —             & —              \\
\end{tabular}


\begin{tabular}{c | c c c c c}
             & \cite{sijsling} & \cite{effectfully} & \cite{practgen} & Shallow   & Deep (old) \\
    \hline   
    Fixpoint & yes             & yes                & no              & yes       & yes     \\
    Index    & equality        & equality           & equality        & equality  &         \\
    Poly     & telescope       & external           & telescope       & telescope &         \\
    Levels   & no***           & cumulative         & Typeω           & Type-in-Type &         \\
    Sums     & list            & large              & list            & list      &         \\
    IndArg   & $X\ pv\ i$      & $\dots\to X\ v\ i$ & $\dots\to X\ pv\ i$ & $X (f pv) i$ & ?1 \\
    Compose  & no              & yes?2              & no              & yes       &         \\
    Extension& —               & yes                & yes             & no        &         \\
    Ignore   & no              & ?                  & ?               & transform &         \\
    Set      & no              & no                 & no              & no        & yes     \\
\end{tabular}



\begin{itemize}
    \item IndArg: the allowed shapes of inductive arguments. Note that none other than Haskell, higher-order functors, and potentially ?1, allow full nested types!
    \item Compose: can a description refer to another description?
    \item Extension: do inductive arguments and end nodes, and sums and products coincide through a top-level extension?
    \item Ignore: can subsequent constructor descriptions ignore values of previous ones? (Either this, or thinnings, are essential to make composites work)
    \item Set: are sets internalized in this description?
\end{itemize}

\begin{itemize}
    \item[*] These descriptions are ``coinductive'' in that they can contain themselves, so the ``fixpoint'' is more like a deep interpretation.
    \item[**] This has no fixpoint, and the generalization over the index is external.
    \item[***] But you could bump the parameter telescope to Typeω and lose nothing.
    \item[*4] A variant keeps track of the highest level in the index.
    \item[?1] Deeply encoding all involved functors would remove the need for positivity annotations for full nested types like in other implementations.
    \item[?2] The ``simplicity'' of this implementation, where data and constructor descriptions coincide, automatically allows composite descriptions.
\end{itemize}

We take away some interesting points from this:
\begin{itemize}
    \item Levels are important, because index-first descriptions are incompatible with ``data-cumulativity'' when not emulating it using equalities! (This results in datatypes being forced to have fields of a fixed level).
    \item Coinductive descriptions can generate inductive types!
    \item Typeω descriptions can generate types of any level!
    \item Large sums do not reflect Agda (a datatype instantiated from a derived description looks nothing like the original type)! On the other hand, they make lists unnecessary, and simplify the definition of ornaments as well.
    \item We can group/collapse multiple signatures into one using tags, this might be nice for defining generic functions in a more collected way.
    \item Everything becomes completely unreadable without opacity.
\end{itemize}

\subsection{Merge me}


\subsubsection{Ornamentation}
While we can derive datastructures from number systems by going through their index types \cite{calcdata}, we may also interpret numerical representations more literally as instructions to rewrite a number system to a container type. We can record this transformation internally using ornaments, which can then be used to derive an indexed version of the container \cite{algorn}, or can be modified further to naturally integrate other constraints, e.g., ordering, into the resulting structure \cite{progorn}. Furthermore, we can also use the forgetful functions induced by ornaments to generate specifications for functions defined on the ornamented types \cite{orntrans}.

\subsubsection{Generic constructions}
Being able to define a datatype and reflect its structure in the same language opens doors to many more interesting constructions \cite{practgen}; a lot of ``recipes'' we recognize, such as defining the eliminators for a given datatype, can be formalized and automated using reflection and macros. We expect that other type transformations can also be interpreted as ornaments, like the extraction of heterogeneous binary trees from level-polymorphic binary trees \cite{hetbin}. 


\subsection{Takeways}
At the very least, descriptions will need sums, products, and recursive positions as well. While we could use coinductive descriptions, bringing normal and recursive fields to the same level, we avoid this as it also makes ornaments a bit more wild\footnote{For better or worse, an ornament could refer to a different ornament for a recursive field.}. We represent indexed types by parametrizing over a type $I$. Since we are aiming for nested types, external polymorphism\footnote{E.g., for each type $A$ a description of lists of $A$ à la \cite{progorn}} does not suffice: we need to let descriptions control their contexts.

We describe parameters by defining descriptions relative to a context. Here, a context is a telescope of types, where each type can depend on all preceding types:
\[ \dots \]
Much like the work Escot and Cockx \cite{practgen} we shove everything into \AgdaFunction{Typeω}, but we do not (yet) allow parameters to depend on previous values, or indices on parameters\footnote{I do not know yet what that would mean for ornaments.}.

We use equalities to enforce indices, simply because index-first types are not honest about being finite, and consequently mess up our levels. For an index type and a context a description represents a list of constructors:
\[ \dots \]
These represent lists of alternative constructors, which each represent a list of fields:
\[ \dots \]
We separate mere fields from ``known'' fields, which are given by descriptions rather than arbitrary types. Note that we do not split off fields to another description, as subsequent fields should be able to depend on previous fields
\[ \dots. \]


We parametrize over the levels, because unlike practical generic, we stay at one level.

Q: what happens when you precompose a datatype with a function? E.g. (List . f) A = List (f A) 

Q: practgen is cool, compact, and probably necessary to have all datatypes. Note that in comparison, most other implementations (like Sijsling) do not allow functions as inductive arguments. Reasonably so.

Q: I should probably update my Agda and make use of the new opaque features to make things readable when refining


\towrite{Adapt this to the non-proposal form.}

\section{The Structure Identity Principle}
If we write a program, and replace an expression by an equal one, then we can prove that the behaviour of the program can not change. Likewise, if we replace one implementation of an interface with another, in such a way that the correspondence respects all operations in the interface, then the implementations should be equal when viewed through the interface. Observations like these are instances of ``representation independence'', but even in languages with an internal notation of type equality, the applicability is usually exclusive to the metatheory.

In our case, moving from Agda's ``usual type theory'' to Cubical Agda, \textit{univalence} \cite{cuagda} lets us internalize a kind of representation independence known as the Structure Identity Principle \cite{iri}, and even generalize it from equivalences to quasi-equivalence relations. 
%a cubical homotopy type theory,
We will also be able to apply univalence to get a true ``equational reasoning'' for types when we are looking at numerical representations.

Still, representation independence in may be internalized outside the homotopical setting in some cases \cite{tgalois}, and remains of interest in the context of generic constructions that conflict with cubical type theory.

\section{Numerical Representations}
Rather than equating implementations after the fact, we can also ``compute'' datastructures by imposing equations. In the case of container types, one may observe similarities to number systems \cite{purelyfunctional} and call such containers numerical representations. One can then use these representations to prototype new datastructures that automatically inherit properties and equalities from their underlying number systems \cite{calcdata}.

From another perspective, numerical representations run by using representability as a kind of ``strictification'' of types. %This suggests that we may be able to generalize the approach of numerical representations, using that any (non-indexed) infinitary inductive-recursive type supports a lookup operation \cite{glookup}.

\printbibliography

\part{Appendix}
\appendix

\section{Finger trees}
\input{Fingertrees}

\section{Heterogenization}
\input{Heterogenization.tex}


\section{More equivalences for less effort}\label{sec:userfriendly}
Noting that constructing equivalences directly or from isomorphisms as in \autoref{ssec:leibniz} can quickly become challenging when one of the sides is complicated, we work out a different approach making use of the initial semantics of W-types instead. We claim that the functions in the isomorphism of \autoref{ssec:leibniz} were partially forced, but this fact was unused there.

First, we explain that if we assume that one of the two sides of the equivalence is a fixpoint or initial algebra of a polynomial functor (that is, the \AgdaDatatype{μ} of a \AgdaDatatype{Desc′}), this simplifies giving an equivalence to showing that the other side is also initial.

We describe how we altered the original ornaments \cite{progorn} to ensure that \AgdaDatatype{μ} remains initial for its base functor in Cubical Agda, explaining why this fails otherwise, and how defining base functors as datatypes avoids this issue.

In a subsection focussing on the categorical point of view, we show how we can describe initial algebras (and truncate the appropriate parts) in such a way that the construction both applies to general types (rather than only sets), and still produces an equivalence at the end. We explain how this definition, like the usual definition, makes sure that a pair of initial objects always induces a pair of conversion functions, which automatically become inverses. Finally, we explain that we can escape our earlier truncation by appealing to the fact that ``being an equivalence'' is a proposition.

Next, we describe some theory, using which other types can be shown to be initial for a given algebra. This is compared to the construction in \autoref{ssec:leibniz}, observing that intuitively, initiality follows because the interpretation of the zero constructor is forced by the square defining algebra maps, and the other values are forced by repeatedly applying similar squares. This is clarified as an instance of recursion over a polynomial functor.

To characterize when this recursion is allowed, we define accessibility with respect to polynomial functors as a mutually recursive datatype as follows. This datatype is constructed using the fibers of the algebra map, defining accessibility of elements of these fibers by cases over the description of the algebra. Then we remark that this construction is an atypical instance of well-founded recursion, and define a type as well-founded for an algebra when all its elements are accessible.

We interpret well-foundedness as an upper bound on the size of a type, leading us to claim that injectivity of the algebra map gives a lower bound, which is sufficient to induce the isomorphism. We sketch the proof of the theorem, relating part of this construction to similar concepts in the formalization of well-founded recursion in the Standard Library. In particular, we prove an irrelevance and an unfolding lemma, which lets us show that the map into any other algebra induced by recursion is indeed an algebra map. By showing that it is also unique, we conclude initiality, and get the isomorphism as a corollary. 

The theorem is applied and demonstrated to the example of binary naturals. We remark that the construction of well-foundedness looks similar to view-patterns. After this, we conclude that this example takes more lines that the direct derivation in \autoref{ssec:leibniz}, but we argue that most of this code can likely be automated.

\towrite{Merge}

\input{UserFriendly}

\end{document}
