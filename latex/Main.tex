\documentclass{article}

\usepackage[style=alphabetic]{biblatex}
\addbibresource{refs.bib}

\usepackage{comment}

\setlength{\marginparwidth}{2cm} % remove when done

\usepackage{todonotes}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}

%\hypersetup{
%    colorlinks=true,
%    linkcolor=cyan
%    }

\usepackage{catchfilebetweentags}
\usepackage{quiver} 
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{longtable}
\usepackage{amsthm}
\usepackage{amsmath}


\theoremstyle{plain}% default
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem*{cor}{Corollary}

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{claim}{Claim}[section]

\renewcommand{\partautorefname}{Part}%
\renewcommand{\sectionautorefname}{Section}%
\renewcommand{\subsectionautorefname}{Subsection}%

\providecommand{\theoremautorefname}{Theorem}%
\providecommand{\lemmaautorefname}{Lemma}%
\providecommand{\propautorefname}{Proposition}%
\providecommand{\corautorefname}{Corollary}%

\providecommand{\defnautorefname}{Definition}%
\providecommand{\remarkautorefname}{Remark}%
\providecommand{\claimautorefname}{Claim}%


\usepackage[links]{agda}
\AgdaNoSpaceAroundCode{}

% from: https://agda.readthedocs.io/en/v2.6.3/_downloads/59877ce886494c991a213f09e29b712c/article-luaxelatex-different-fonts.lagda.tex
\usepackage{fontspec}

\usepackage{luaotfload}

\directlua{luaotfload.add_fallback
  ("myfallback",
    { "JuliaMono:style=Regular;"
    , "NotoSansMono:style=Regular;"
    , "NotoSansMath:style=Regular;"
    , "Segoe UI Emoji:mode=harf;"
    }
  )}
\defaultfontfeatures{RawFeature={fallback=myfallback}}

\setmainfont{Latin Modern Roman}

\newfontfamily{\AgdaSerifFont}{Linux Libertine O}
\newfontfamily{\AgdaSansSerifFont}{Linux Biolinum O}
\newfontfamily{\AgdaTypewriterFont}{inconsolata}
\renewcommand{\AgdaFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaKeywordFontStyle}[1]{{\AgdaSansSerifFont{}#1}}
\renewcommand{\AgdaStringFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaCommentFontStyle}[1]{{\AgdaTypewriterFont{}#1}}
\renewcommand{\AgdaBoundFontStyle}[1]{\textit{\AgdaSerifFont{}#1}}

\newcommand{\towrite}[1]{\par\textcolor{blue}{Write here about: ``#1''}\par}
\newcommand{\toremove}[1]{\textcolor{red}{This is going to be (re)moved: ``#1''}}


% macros
\newcommand{\investigate}[1]{\par\vspace{1\baselineskip}\textcolor{gray}{\textit{#1}}\vspace{1\baselineskip}\par}

% symbols
\newcommand{\bN}{\AgdaDatatype{ℕ}}
\newcommand{\bL}{\AgdaDatatype{Leibniz}}


\title{Ornaments and Proof Transport applied to Numerical Representations}
\author{Samuel Klumpers\\6057314}

% previous (provisional) titles:
% Restoring (part of) the friendship between recursion schemes and without-K (provisional)
% The gentle art of smashing things to bits and pieces
% Running in circles in Agda

\begin{document}
\maketitle

%This document is generated from a literate agda file!
%\newpage

\begin{abstract}
%\towrite{Provisional}
This thesis explains the concepts of the structure identity principle, numerical representations, and ornaments, and aims to combine these to simplify the presentation and verification of finger trees, demonstrating the generalizability and improved compactness and security of the resulting code. Consequently, we also investigate to which extent ornaments, and other generic programs relying on axiom K, remain applicable in the cubical setting required for the structure identity principle.
\end{abstract}

\tableofcontents

\begin{comment}
\section*{Outline}
In this document I propose a master thesis project, in which I will investigate and attempt to counter the obstacles one can encounter when replacing one datastructure with a more complicated one, focussing on how we can retain or reuse properties and proofs from the simpler datastructure.

We introduce the topics of proof transport, ornamentation, and numerical representation by presenting problems and explaining how these topics can be applied to them. Following up on these problems, we make our research question more precise, list some related questions, and propose methods by which we may answer these questions. We then overview related research and existing theory, highlighting the problems they originally solved, and how we may apply them to our research question. Next, we summarize preliminary work done for this project. Finally, we propose a planning, explaining more precisely how we split the research question into parts and what subproblems we intend to solve working towards answering our research question.
\end{comment}


\section{Introduction}\label{sec:intro}
\input{Introduction}

\subsection{The Problem}

\subsection{Contributions}


\section{Background}
\input{Background}

\section{Preliminary work}\label{sec:preliminary}
\towrite{Adapt and split into background and actual work}

\section{Proof Transport via the Structure Identity Principle}\label{sec:leibniz}
To give an understanding of the basics of Cubical Agda \cite{cuagda} and the Structure Identity Principle (SIP), we walk through the steps to transport proofs about addition on Peano naturals to Leibniz naturals. We give an overview of some features of Cubical Agda, such as that paths give the primitive notion of equality, until the simplified statement of univalence. We do note that Cubical Agda has two downsides relating to termination checking and universe levels, which we encounter in later sections.

Starting by defining the unary Peano naturals and the binary Leibniz naturals, we prove that they are isomorphic by interpreting them into eachother. We explain that these interpretations are easily seen to be mutual inverses by proving lemmas stating that both interpretations ``respect the constructors'' of the types. Next, we demonstrate how this isomorphism can be promoted into an equivalence or an equality, and remark that this is sufficient to transport intrinsic properties, such as having decidable equality, from one natural to the other.

Noting that transporting unary addition to binary addition is possible but not efficient, we define binary addition while ensuring that it corresponds to unary addition. We present a variant on refinement types as a syntax to recover definition from chains of equality reasoning, allowing one to rewrite definitions while preserving equalities.

We clarify that to transport proofs referring to addition from unary to binary naturals, we indeed require that these are meaningfully related. Then, we observe that in this instance, the pairs of ``type and operation'' are actually equated as magmas, and explain that this is an instance of the SIP.

Finally, we describe the use case of the SIP, how it generalizes our observation about magmas, and how it can calculate the minimal requirements to equate to implementations of an interface. This is demonstrated by transporting associativity from unary addition to binary addition, noting that this would save many lines of code provided there is much to be transported.

\towrite{Merge}

\input{CubicalAndBinary}


\section{Types from Specifications: Ornamentation and Calculation}\label{sec:numrep}
Using an example where we try to safely refactor a piece of code to use trees rather than lists, we motivate the need for a framework to organize different container types under a similar description. We explain that for indexed types, we can use representability, e.g., vectors correspond to functions out of finite types.

We describe how we can also derive these datastructures from functions \cite{calcdata}, starting from a number system, yielding a numerical representation \cite{purelyfunctional}; this is demonstrated by an example deriving of vectors from unary naturals \cite{calcdata}. The vector type is computed by chains of equality reasoning like in the previous section, giving the correspondence to functions out of the finite type.

We illustrate how both (the functions out of a type and the concrete vectors) can implement an array interface, such as two-sided flexible arrays. We remark that the laws for such interfaces can be more easily proven on the function-based implementations, so that they can be transported to the concrete implementation.

Reflecting on this derivation, we note that the computation for binary naturals would be analogous, amending constructors constructors with fields holding appropriate number of elements. We relate this to ornamentation \cite{progorn}, which lets us relate types by recursive structure. After that, we give a short overview of the capabilities of descriptions and ornaments, and demonstrate these by deriving the list datatype from the unary natural type using an ornamental description.

We remark that this approach needs to be adjusted to use indices before it can be applied to binary naturals; we clarify how ``metaphorical'' this construction of binary trees is to binary numbers by letting the weight of the ``digits'' control the numbers of elements in each constructor. We explain that in doing so, the shape of the binary tree seen as a binary number then corresponds to the number of elements it contains.

After that, we give a completely different application of ornaments; we recall that the construction of heterogeneous lists, lists which contain elements with different types, is rather mechanical. Observing that a ``heterogeneous X'' is expressed as an ``X-indexed X'', we assert that this self-indexing can be captured as an ornament.

To define this ornament, we needed to include a parameter field in the definition of descriptions and ornaments. Then we define ``heterogeneization'' as an ``ornament-computing function'', which takes a description and produces an ornamental description. We demonstrate how we can heterogeneize lists and maybes, allowing us to produce a natural implementation of the heterogeneous head operation, and relate this to earlier work deriving heterogeneous random access lists \cite{hetbin}.

\towrite{Merge}

\input{TypeGeneration}

\section{More equivalences for less effort}\label{sec:userfriendly}
Noting that constructing equivalences directly or from isomorphisms as in \autoref{sec:leibniz} can quickly become challenging when one of the sides is complicated, we work out a different approach making use of the initial semantics of W-types instead. We claim that the functions in the isomorphism of \autoref{sec:leibniz} were partially forced, but this fact was not made use of.

First, we explain that if we assume that one of the two sides of the equivalence is a fixpoint or initial algebra of a polynomial functor (that is, the \AgdaDatatype{μ} of a \AgdaDatatype{Desc′}), this simplifies giving an equivalence to showing that the other side is also initial.

We describe how we altered the original ornaments \cite{progorn} to ensure that \AgdaDatatype{μ} remains initial for its base functor in Cubical Agda, explaining why this fails otherwise, and how defining base functors as datatypes avoids this issue.

In a subsection focussing on the categorical point of view, we show how we can describe initial algebras (and truncate the appropriate parts) in such a way that the construction both applies to general types (rather than only sets), and still produces an equivalence at the end. We explain how this definition, like the usual definition, makes sure that a pair of initial objects always induces a pair of conversion functions, which automatically become inverses. Finally, we explain that we can escape our earlier truncation by appealing to the fact that ``being an equivalence'' is a proposition.

Next, we describe some theory, using which other types can be shown to be initial for a given algebra. This is compared to the construction in \autoref{sec:leibniz}, observing that intuitively, initiality follows because the interpretation of the zero constructor is forced by the square defining algebra maps, and the other values are forced by repeatedly applying similar squares. This is clarified as an instance of recursion over a polynomial functor.

To characterize when this recursion is allowed, we define accessibility with respect to polynomial functors as a mutually recursive datatype as follows. This datatype is constructed using the fibers of the algebra map, defining accessibility of elements of these fibers by cases over the description of the algebra. Then we remark that this construction is an atypical instance of well-founded recursion, and define a type as well-founded for an algebra when all its elements are accessible.

We interpret well-foundedness as an upper bound on the size of a type, leading us to claim that injectivity of the algebra map gives a lower bound, which is sufficient to induce the isomorphism. We sketch the proof of the theorem, relating part of this construction to similar concepts in the formalization of well-founded recursion in the Standard Library. In particular, we prove an irrelevance and an unfolding lemma, which lets us show that the map into any other algebra induced by recursion is indeed an algebra map. By showing that it is also unique, we conclude initiality, and get the isomorphism as a corrolary. 

The theorem is applied and demonstrated to the example of binary naturals. We remark that the construction of well-foundedness looks similar to view-patterns. After this, we conclude that this example takes more lines that the direct deriviation in \autoref{sec:leibniz}, but we argue that most of this code can likely be automated.

\towrite{Merge}

\input{UserFriendly}


\section{Enumeration}
\input{Enumeration.tex}



\begin{comment}
\section{FingerTrees}\label{sec:fingertrees}
Finger trees are often (rightfully so) referred to as ``the fastest persistent datastructure for most purposes'', but while simpler than implementations achieving the same bounds, they are still challenging to reason about; in this section, we will investigate how we can fit the description and analysis of fingertrees, or variants upon them, into the frameworks of calculating datastructures and ornamental programming.

We compare the work in calculating datastructures to solving associativity equations in groups by shifting to the Cayley representation, such as in [..]


%\section{Discussion and Future Work}\label{sec:discussion}


\newpage
\section{Temporary}\label{sec:temp}
\listoftodos
%\subfile{Scratch.tex}
\end{comment}



\section{Related work}\label{sec:resources}
\towrite{Adapt this to the non-proposal form}

\subsection{The Structure Identity Principle}
If we write a program, and replace an expression by an equal one, then we can prove that the behaviour of the program can not change. Likewise, if we replace one implementation of an interface with another, in such a way that the correspondence respects all operations in the interface, then the implementations should be equal when viewed through the interface. Observations like these are instances of ``representation indepencence'', but even in languages with an internal notation of type equality, the applicability is usually exclusive to the metatheory.

In our case, moving from Agda's ``usual type theory'' to Cubical Agda, a cubical homotopy type theory, \textit{univalence} \cite{cuagda} lets us internalize a kind of representation independence known as the Structure Identity Principle \cite{iri}, and even generalize it from equivalences to quasi-equivalence relations. We will also be able to apply univalence to get a true ``equational reasoning'' for types when we are looking at numerical representations.

Still, representation independence in non-homotopical settings may be internalized in some cases \cite{tgalois}, and remains of interest in the context of generic constructions that conflict with cubical.

\subsection{Numerical Representations}
Rather than equating implementations after the fact, we can also ``compute'' datastructures by imposing equations. In the case of container types, one may observe similarities to number systems \cite{purelyfunctional} and call such containers numerical representations. One can then use these representations to prototype new datastructures that automatically inherit properties and equalities from their underlying number systems \cite{calcdata}.

From another perspective, numerical representations run by using representability as a kind of ``strictification'' of types, suggesting that we may be able to generalize the approach of numerical representations, using that any (non-indexed) infinitary inductive-recursive type supports a lookup operation \cite{glookup}.

% In the original setup \cite{calcdata}, the chains of equality reasoning over types had to be unfolded to transport a property from ``natural lookup tables'' to vectors. We expect that one might generalize the SIP to support indexed types, and use this to directly transport proofs from one side of the equality to the other.

\subsection{Ornamentation}
While we can derive datastructures from number systems by going through their index types \cite{calcdata}, we may also interpret numerical representations more literally as intstructions to rewrite a number system to a container type. We can record this transformation internally using ornaments, which can then be used to derive an indexed version of the container \cite{algorn}, or can be modified further to naturally integrate other constraints, e.g., ordering, into the resulting structure \cite{progorn}. Furthermore, we can also use the forgetful functions induced by ornaments to generate specifications for functions defined on the ornamented types \cite{orntrans}.

\subsection{Generic constructions}
Being able to define a datatype and reflect its structure in the same language opens doors to many more interesting constructions \cite{practgen}; a lot of ``recipes'' we recognize, such as defining the eliminators for a given datatype, can be formalized and automated using reflection and macros. We expect that other type transformations can also be interpreted as ornaments, like the extraction of heterogeneous binary trees from level-polymorphic binary trees \cite{hetbin}. 



% \input{Proposal.tex}



\printbibliography
\end{document}
